import instaloader
from pathlib import Path
import pandas as pd
from datetime import datetime
import whisper
import requests
import tempfile
import os
import subprocess
import openai
from api_config import get_api_config

# ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path("D:/cursor_ai/02_reels_benchmarking_template")

def extract_audio(video_path, output_path):
    try:
        # FFmpeg ëª…ë ¹ì–´ë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        command = [
            'ffmpeg',
            '-i', video_path,  # ì…ë ¥ ë¹„ë””ì˜¤
            '-vn',  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì œê±°
            '-acodec', 'pcm_s16le',  # ì˜¤ë””ì˜¤ ì½”ë±
            '-ar', '16000',  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
            '-ac', '1',  # ëª¨ë…¸ ì±„ë„
            '-y',  # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
            output_path
        ]
        
        subprocess.run(command, check=True, capture_output=True)
        return output_path
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

def download_video(url):
    response = requests.get(url)
    if response.status_code == 200:
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as tmp_file:
            tmp_file.write(response.content)
            return tmp_file.name
    return None

def transcribe_video(video_path):
    try:
        # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        temp_audio = tempfile.NamedTemporaryFile(suffix='.wav', delete=False).name
        
        # ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_path = extract_audio(video_path, temp_audio)
        if not audio_path:
            return ""
            
        # Whisper ëª¨ë¸ë¡œ ìŒì„± ì¸ì‹
        model = whisper.load_model("small")
        result = model.transcribe(audio_path)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(audio_path)
        
        return result["text"]
        
    except Exception as e:
        print(f"ì „ì‚¬ ì˜¤ë¥˜: {e}")
        return ""

def translate_to_korean(text):
    """ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë˜, íŠ¹ìˆ˜ë¬¸ìì™€ ì´ëª¨í‹°ì½˜ì€ ìœ ì§€í•©ë‹ˆë‹¤."""
    try:
        api_config = get_api_config()
        client = openai.OpenAI(api_key=api_config["api_key"])
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë‹¨, ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:
        1. ì „ë¬¸ ìš©ì–´ë‚˜ ë¸Œëœë“œëª… ë“± í•œêµ­ì–´ë¡œ ë²ˆì—­ì´ ì–´ë ¤ìš´ ì˜ì–´ ë‹¨ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€
        2. ì´ëª¨í‹°ì½˜ê³¼ íŠ¹ìˆ˜ë¬¸ì(ì˜ˆ: âœ¨, ğŸ”¥, #)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
        3. í•´ì‹œíƒœê·¸ëŠ” ì˜ì–´ë¡œ ëœ ê²½ìš° ì›ë¬¸ ìœ ì§€
        
        ì›ë¬¸:
        {text}
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=1000
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return text

def refine_transcript(transcript, caption, video_analysis):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì •ì œí•˜ê³  í•„ìš”í•œ ê²½ìš° í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    """
    try:
        # ë¨¼ì € ìŠ¤í¬ë¦½íŠ¸ ì •ì œ
        api_config = get_api_config()
        client = openai.OpenAI(api_key=api_config["api_key"])
        
        prompt = f"""
        ë‹¤ìŒì€ ì˜ìƒì—ì„œ ì¶”ì¶œëœ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ìº¡ì…˜ê³¼ ì˜ìƒ ë¶„ì„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜¤íƒˆìì™€ ì˜ëª» ì¸ì‹ëœ ë‹¨ì–´ë“¤ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
        
        ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸:
        {transcript}
        
        ì°¸ê³ í•  ìº¡ì…˜:
        {caption}
        
        ì˜ìƒ ë¶„ì„ ë‚´ìš©:
        - ì´ˆë°˜ 3ì´ˆ (ì¹´í”¼ë¼ì´íŒ…): {video_analysis.get('intro_copy', '')}
        - ì´ˆë°˜ 3ì´ˆ (ì˜ìƒ êµ¬ì„±): {video_analysis.get('intro_structure', '')}
        - ë‚˜ë ˆì´ì…˜: {video_analysis.get('narration', '')}
        
        ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”. ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        refined_text = response.choices[0].message.content.strip()
        
        # ì˜ì–´ë¡œ ëœ ê²½ìš° í•œêµ­ì–´ë¡œ ë²ˆì—­
        if any(ord(c) < 128 for c in refined_text):  # ì˜ì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            refined_text = translate_to_korean(refined_text)
            
        return refined_text
    except Exception as e:
        print(f"ìŠ¤í¬ë¦½íŠ¸ ì •ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return transcript

def extract_reels_info(url, video_analysis=None):
    # Instaloader ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    L = instaloader.Instaloader()
    
    # URLì—ì„œ ìˆì½”ë“œ ì¶”ì¶œ
    shortcode = url.split("/p/")[1].strip("/")
    
    try:
        # ê²Œì‹œë¬¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        post = instaloader.Post.from_shortcode(L.context, shortcode)
        
        # ê²°ê³¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = BASE_DIR / "reels_output"
        output_dir.mkdir(exist_ok=True, parents=True)
        
        # ë¹„ë””ì˜¤ URLê³¼ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        video_url = post.video_url
        video_path = download_video(video_url)  # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        
        # ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
        transcript = transcribe_video(video_path) if video_path else ""
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if video_path:
            Path(video_path).unlink()
        
        # ìŒì•… ì •ë³´ ì¶”ì¶œ ì‹œë„
        try:
            music_info = post.media_info.get('music_info', {})
            music_title = music_info.get('title', '')
            music_artist = music_info.get('artist', '')
        except:
            music_title = ''
            music_artist = ''
        
        # ì •ë³´ ì¶”ì¶œ
        info = {
            'shortcode': shortcode,
            'date': post.date.strftime('%Y-%m-%d %H:%M:%S'),
            'raw_transcript': transcript,
            'caption': post.caption if post.caption else "",
            'view_count': post.video_view_count if hasattr(post, 'video_view_count') else 0,
            'video_duration': post.video_duration if hasattr(post, 'video_duration') else 0,
            'likes': post.likes,
            'comments': post.comments,
            'music_title': music_title,
            'music_artist': music_artist,
            'owner': post.owner_username,
            'video_url': video_url
        }
        
        # ìº¡ì…˜ì´ ì˜ì–´ì¸ ê²½ìš° í•œêµ­ì–´ë¡œ ë²ˆì—­
        if info['caption'] and any(ord(c) < 128 for c in info['caption']):
            info['caption'] = translate_to_korean(info['caption'])
        
        # ìŠ¤í¬ë¦½íŠ¸ ì •ì œ ìˆ˜í–‰
        refined_transcript = refine_transcript(
            transcript,
            info['caption'],
            video_analysis or {}
        )
        info['refined_transcript'] = refined_transcript
        
        return info
        
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {str(e)}"